{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-01T18:29:55.457108Z",
     "start_time": "2024-07-01T18:29:54.306335Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tortreinador.utils.tools import check_outlier\n",
    "from tortreinador.utils.plot import plot_line_2\n",
    "from tortreinador.utils.preprocessing import load_data\n",
    "from tortreinador.train import TorchTrainer\n",
    "from tortreinador.models.MDN import Mixture, NLLLoss\n",
    "from Rock.Model.EnsembleMDN import EnsembleMDN\n",
    "from tortreinador.utils.View import init_weights, split_weights\n",
    "from tortreinador.utils.plot import calculate_GMM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tortreinador.utils.metrics import r2_score\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import proplot as pplt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825bd0c8e296bf09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:29:55.801724Z",
     "start_time": "2024-07-01T18:29:55.458105Z"
    }
   },
   "outputs": [],
   "source": [
    "df_chunk_0 = pd.read_parquet(\"D:\\\\Resource\\\\rockyExoplanetV3\\\\data_chunk_0.parquet\")\n",
    "df_chunk_1 = pd.read_parquet(\"D:\\\\Resource\\\\rockyExoplanetV3\\\\data_chunk_1.parquet\")\n",
    "\n",
    "df_all = pd.concat([df_chunk_0, df_chunk_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c9f7df9600b078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:29:55.817139Z",
     "start_time": "2024-07-01T18:29:55.802720Z"
    }
   },
   "outputs": [],
   "source": [
    "input_parameters = [\n",
    "    'Mass',\n",
    "    'Radius',\n",
    "    'FeMg',\n",
    "    'SiMg',\n",
    "    'Mass_Noise',\n",
    "    'Radius_Noise',\n",
    "    'FeMg_Noise',\n",
    "    'SiMg_Noise'\n",
    "]\n",
    "\n",
    "output_parameters = [\n",
    "    'WRF',\n",
    "    'MRF',\n",
    "    'CRF',\n",
    "    'WMF',\n",
    "    'CMF',\n",
    "    'CPS',\n",
    "    'CTP',\n",
    "    'k2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c73aff4530d407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:29:55.833178Z",
     "start_time": "2024-07-01T18:29:55.818136Z"
    }
   },
   "outputs": [],
   "source": [
    "offset_rate = np.array([0.04, 0.02, 0.12, 0.14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cebdcc6a76ebd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:29:55.913181Z",
     "start_time": "2024-07-01T18:29:55.836179Z"
    }
   },
   "outputs": [],
   "source": [
    "input_df_4 = df_all[input_parameters[:4]]\n",
    "\n",
    "# calculate the sigma\n",
    "sigma = input_df_4.mul(offset_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b489e1dd52f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:29:55.929181Z",
     "start_time": "2024-07-01T18:29:55.914178Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_noise(x):\n",
    "    return float(np.random.normal(0, x, size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496c4f06900fa5dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:23.700166Z",
     "start_time": "2024-07-01T18:29:55.930182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Noise\n",
    "noise = pd.DataFrame()\n",
    "for i in input_parameters[:4]:\n",
    "    tmp = sigma[i].apply(generate_noise)\n",
    "    noise = pd.concat([noise, tmp], axis=1)\n",
    "\n",
    "# Add Noise\n",
    "noise_added_data = input_df_4 + noise\n",
    "noise_added_data.columns = [\n",
    "    'Mass_Noise',\n",
    "    'Radius_Noise',\n",
    "    'FeMg_Noise',\n",
    "    'SiMg_Noise',\n",
    "]\n",
    "\n",
    "df_merged = pd.concat([df_all, noise_added_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2149dd724d3cace5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:26.280348Z",
     "start_time": "2024-07-01T18:30:23.701166Z"
    }
   },
   "outputs": [],
   "source": [
    "t_loader, v_loader, test_x, test_y, s_x, s_y = load_data(data=df_merged, input_parameters=input_parameters,\n",
    "                                                         output_parameters=output_parameters,\n",
    "                                                         if_normal=True, if_shuffle=True, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f080f031c0e30371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:26.311934Z",
     "start_time": "2024-07-01T18:30:26.281346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = EnsembleMDN(input_size=int(len(input_parameters) / 2), output_size=len(output_parameters), num_hidden=256, num_gaussian=20, kernel_size=2)\n",
    "init_weights(model)\n",
    "criterion = NLLLoss()\n",
    "optimizer = torch.optim.Adam(split_weights(model), lr=0.0001, weight_decay=0.0001)\n",
    "mixture = Mixture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2492d240fd7efc56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:26.327935Z",
     "start_time": "2024-07-01T18:30:26.312933Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(TorchTrainer):\n",
    "    def calculate(self, x, y, mode='t'):\n",
    "        x_o, x_n = x.chunk(2, dim=1)\n",
    "        \n",
    "        pi, mu, sig = model(x_o, x_n)\n",
    "        \n",
    "        loss = self.criterion(pi, mu, sig, y)\n",
    "        pdf = mixture(pi, mu, sig)\n",
    "        y_pred = pdf.sample()\n",
    "        \n",
    "        metric_per = r2_score(y, y_pred)\n",
    "        return self._standard_return(loss=loss, metric_per=metric_per, mode=mode, y=y, y_pred=y_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a42684eceeb451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:26.375444Z",
     "start_time": "2024-07-01T18:30:26.328936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:200, is GPU: True\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(is_gpu=True, epoch=200, optimizer=optimizer, model=model, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "362398acf9fdd22a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:26.391445Z",
     "start_time": "2024-07-01T18:30:26.376444Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'b_m': 0.8,\n",
    "    'm_p': 'D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\',\n",
    "    'w_e': 5,\n",
    "    # 'l_m': {\n",
    "    #     's_l': [18, 48, 84, 100, 113, 124, 133],\n",
    "    #     'gamma': 0.7\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379b3cb2f936bdad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T18:30:32.329167Z",
     "start_time": "2024-07-01T18:30:26.392443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.mdn_original.root_layer.0.weight : torch.Size([256, 4])\n",
      "module.mdn_original.root_layer.0.bias : torch.Size([256])\n",
      "module.mdn_original.root_layer.2.weight : torch.Size([256, 256])\n",
      "module.mdn_original.root_layer.2.bias : torch.Size([256])\n",
      "module.mdn_original.root_layer.4.weight : torch.Size([256, 256])\n",
      "module.mdn_original.root_layer.4.bias : torch.Size([256])\n",
      "module.mdn_original.pi.0.weight : torch.Size([256, 256])\n",
      "module.mdn_original.pi.0.bias : torch.Size([256])\n",
      "module.mdn_original.pi.2.weight : torch.Size([20, 256])\n",
      "module.mdn_original.pi.2.bias : torch.Size([20])\n",
      "module.mdn_original.mu.0.weight : torch.Size([256, 256])\n",
      "module.mdn_original.mu.0.bias : torch.Size([256])\n",
      "module.mdn_original.mu.2.weight : torch.Size([160, 256])\n",
      "module.mdn_original.mu.2.bias : torch.Size([160])\n",
      "module.mdn_original.sigma.0.weight : torch.Size([256, 256])\n",
      "module.mdn_original.sigma.0.bias : torch.Size([256])\n",
      "module.mdn_original.sigma.2.weight : torch.Size([160, 256])\n",
      "module.mdn_original.sigma.2.bias : torch.Size([160])\n",
      "module.mdn_noise.root_layer.0.weight : torch.Size([256, 4])\n",
      "module.mdn_noise.root_layer.0.bias : torch.Size([256])\n",
      "module.mdn_noise.root_layer.2.weight : torch.Size([256, 256])\n",
      "module.mdn_noise.root_layer.2.bias : torch.Size([256])\n",
      "module.mdn_noise.root_layer.4.weight : torch.Size([256, 256])\n",
      "module.mdn_noise.root_layer.4.bias : torch.Size([256])\n",
      "module.mdn_noise.pi.0.weight : torch.Size([256, 256])\n",
      "module.mdn_noise.pi.0.bias : torch.Size([256])\n",
      "module.mdn_noise.pi.2.weight : torch.Size([20, 256])\n",
      "module.mdn_noise.pi.2.bias : torch.Size([20])\n",
      "module.mdn_noise.mu.0.weight : torch.Size([256, 256])\n",
      "module.mdn_noise.mu.0.bias : torch.Size([256])\n",
      "module.mdn_noise.mu.2.weight : torch.Size([160, 256])\n",
      "module.mdn_noise.mu.2.bias : torch.Size([160])\n",
      "module.mdn_noise.sigma.0.weight : torch.Size([256, 256])\n",
      "module.mdn_noise.sigma.0.bias : torch.Size([256])\n",
      "module.mdn_noise.sigma.2.weight : torch.Size([160, 256])\n",
      "module.mdn_noise.sigma.2.bias : torch.Size([160])\n",
      "module.attn.weight : torch.Size([1, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11025 [00:00<?, ?batch/s]E:\\anaconda\\envs\\deeplearning\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Epoch 1 Training:   0%|          | 0/11025 [00:05<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10620\\3834809361.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\anaconda\\envs\\deeplearning\\lib\\site-packages\\tortreinador\\train.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, t_l, v_l, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m                     \u001B[0mparam_options\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcal_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalculate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmini_batch_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmini_batch_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m't'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m                     \u001B[0mparam_options\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'lr'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'param_groups'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'lr'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'.6f'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\envs\\deeplearning\\lib\\site-packages\\tortreinador\\train.py\u001B[0m in \u001B[0;36mcal_result\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcal_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m't'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_loss_recorder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_metric_recorder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m             return {\n",
      "\u001B[1;32mE:\\anaconda\\envs\\deeplearning\\lib\\site-packages\\tortreinador\\utils\\Recorder.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, val)\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mval\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mval\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdouble\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mavg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "result = trainer.fit(t_loader, v_loader, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc793fb944700ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.331167Z"
    }
   },
   "outputs": [],
   "source": [
    "result_pd = pd.DataFrame()\n",
    "result_pd['epoch'] = range(200)\n",
    "result_pd['train_loss_avg'] = result[0].val.detach().cpu().numpy()\n",
    "result_pd['validation_loss_avg'] = result[1].val.detach().cpu().numpy()\n",
    "\n",
    "plot_line_2(y_1='train_loss_avg', y_2='validation_loss_avg', df=result_pd.iloc[3:, :], output_path=\".\\\\imgs\\\\ROCKYEXO_ENABLEMDN20240630_TrainValLoss_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "check_outlier(result[1].val.detach().cpu().numpy(), 1, 15, 3.0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd2ef1592a99701",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b9937af1e2360",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.332166Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\test_x.npy', test_x)\n",
    "np.save('D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\test_y.npy', test_y)\n",
    "joblib.dump(s_x, \"D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\MDN_v3_Xscaler_20240630.save\")\n",
    "joblib.dump(s_y, \"D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\MDN_v3_yscaler_20240630.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c859d582bd7805",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.333166Z"
    }
   },
   "outputs": [],
   "source": [
    "t_x = np.load(\"D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\test_x.npy\")\n",
    "t_y = np.load(\"D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\test_y.npy\")\n",
    "m_y = joblib.load(\"D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\testData\\\\MDN_v3_yscaler_20240630.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45295e5e1ecbb9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.333166Z"
    }
   },
   "outputs": [],
   "source": [
    "model = EnsembleMDN(int(len(input_parameters) / 2), len(output_parameters), 20, 512, kernel_size=3)\n",
    "init_weights(model)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"D:\\\\Resource\\\\MDN\\\\rockyExoplanetV3\\\\NoiseADD\\\\best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b8eab85a238c3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.334166Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_idx = torch.randint(0, t_x.shape[0], size=(20000, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16a14d75cadeb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.335166Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_test_x = t_x[rand_idx]\n",
    "sampled_test_y = t_y[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe135a2dfe2e49",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.335166Z"
    }
   },
   "outputs": [],
   "source": [
    "t_x_o, t_x_n = np.array_split(sampled_test_x, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351be5b95f2fa488",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.336166Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(torch.from_numpy(t_x_o), torch.from_numpy(t_x_n))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mix = Mixture()\n",
    "criterion = NLLLoss()\n",
    "mse = nn.MSELoss()\n",
    "sample = mix(pred[0], pred[1], pred[2]).sample()\n",
    "print(\"NLLLoss: {}, MSE: {}, R2: {}\".format(criterion(pred[0], pred[1], pred[2], torch.from_numpy(sampled_test_y).to('cuda')),\n",
    "                                            mse(torch.from_numpy(sampled_test_y).to('cuda'), sample),\n",
    "                                            r2_score(sample, torch.from_numpy(sampled_test_y).to('cuda'))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.336166Z"
    }
   },
   "id": "512eeb1939ed3026",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9810d163ad15d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.337166Z"
    }
   },
   "outputs": [],
   "source": [
    "GMM_PDF_scaled = calculate_GMM(torch.exp(pred[0]).detach().cpu().numpy(), pred[1].detach().cpu().numpy(), pred[2].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517626063bb9d6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.338166Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_test_y_inverse = s_y.inverse_transform(sampled_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44feb41ee01ed8dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.338166Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.cm.hot_r\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=1)\n",
    "fig, axs = pplt.subplots(\n",
    "#     figsize=(4,4),\n",
    "    nrows=2, ncols=4,\n",
    "    share=False, \n",
    "    figsize=(12, 8)\n",
    "#     tight=True,\n",
    ")\n",
    "\n",
    "output_parameters = [\n",
    "    'WRF',\n",
    "    'MRF',\n",
    "    'CRF',\n",
    "    'WMF',\n",
    "    'CMF', \n",
    "    'CPS',\n",
    "    'CTP',\n",
    "    'k2'\n",
    "]\n",
    "\n",
    "\n",
    "xlabels = [\n",
    "    \"Actual WRF\",\"Actual MRF\", \"Actual CRF\", \n",
    "    \"Actual WMF\",\"Actual CMF\", \"Actual CMB pressure (GPa)\", \"Actual CMB temperature (K)\",\n",
    "    \"Actual k2\", \n",
    "]\n",
    "ylabels = [\n",
    "    \"Predicted WRF\",\"Predicted MRF\", \"Predicted CRF\", \n",
    "    \"Predicted WMF\",\"Predicted CMF\", \"Predicted CMB pressure (GPa)\", \"Predicted CMB temperature (K)\",\n",
    "    \"Predicted k2\", \n",
    "]\n",
    "\n",
    "xlocators = [\n",
    "    0.04, 0.2, 0.2, 0.02, 0.2, 400, 1000, 0.2\n",
    "]\n",
    "xminorlocators = [\n",
    "    0.004, 0.02, 0.02, 0.02, 40, 100, 0.04, 0.004\n",
    "]\n",
    "\n",
    "OUTPUT_DIMS = len(output_parameters)\n",
    "\n",
    "for o in range(OUTPUT_DIMS):\n",
    "    y_max = max(sampled_test_y_inverse[:, o])\n",
    "    y_min = min(sampled_test_y_inverse[:, o])\n",
    "    for i in range(0, GMM_PDF_scaled.shape[-1], OUTPUT_DIMS):\n",
    "        tx, ty = [sampled_test_y_inverse[int(i / OUTPUT_DIMS), o], y_min]\n",
    "        axs[o].imshow(\n",
    "                GMM_PDF_scaled[:, o + i].reshape(-1, 1),\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                origin='lower',\n",
    "                extent=(tx, tx + 0.0001, ty, y_max)\n",
    "            )\n",
    "\n",
    "    axs[o].plot([y_min, y_max], [y_min, y_max], c='cornflowerblue', ls='--')\n",
    "    axs[o].format(\n",
    "        xlim=(y_min, y_max), ylim=(y_min, y_max),\n",
    "        xlabel=xlabels[o], ylabel=ylabels[o],\n",
    "        xlocator=xlocators[o], xminorlocator=xminorlocators[o],\n",
    "        # ylocator=xlocators[o], yminorlocator=xminorlocators[o]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fae4eb8c21431",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.339166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the offset of the probability density heatmap\n",
    "col_dis = []\n",
    "for o in range(len(output_parameters)):\n",
    "    dis = 0\n",
    "    for i in range(0, GMM_PDF_scaled.shape[-1], len(output_parameters)):\n",
    "        test_y_current = sampled_test_y_inverse[int(i / len(output_parameters)), o]\n",
    "        GMM_cal = GMM_PDF_scaled[:, o + i].reshape(-1, 1)\n",
    "        offset = np.sqrt((GMM_cal - test_y_current) ** 2)\n",
    "        dis += np.mean(offset)\n",
    "    col_dis.append(dis / len(sampled_test_y_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-01T18:30:32.339166Z"
    }
   },
   "id": "bfb8c871ae2b6e33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
